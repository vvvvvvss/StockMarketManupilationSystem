{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLhmksjouCUazbhwHkr6mm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvvvvvss/StockMarketManupilationSystem/blob/main/Stock_ManupilationV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MARCH PROGRESS"
      ],
      "metadata": {
        "id": "lDV6OmlTuNYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-time data processing and analysis"
      ],
      "metadata": {
        "id": "VKCdRf2Jj3Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install aiohttp pandas confluent-kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_40dDFqZjYIv",
        "outputId": "cc139140-0640-4c0a-981c-69bfb25e8d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.11.14)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: confluent-kafka in /usr/local/lib/python3.11/dist-packages (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.18.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to see what kind of data can be fetched from the API: Alphavantage"
      ],
      "metadata": {
        "id": "Kehg7vij0PE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "API_KEY = \"QT13WY791JO16QMJ\"\n",
        "BASE_URL = \"https://www.alphavantage.co/query\"\n",
        "\n",
        "def fetch_stock_data(symbol, interval=\"5min\"):\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_INTRADAY\",\n",
        "        \"symbol\": symbol,\n",
        "        \"interval\": interval,\n",
        "        \"apikey\": API_KEY,\n",
        "        \"outputsize\": \"compact\"\n",
        "    }\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    if \"Error Message\" in data:\n",
        "        print(f\"Error fetching data for {symbol}: {data['Error Message']}\")\n",
        "        return None\n",
        "    elif f\"Time Series ({interval})\" in data:\n",
        "        time_series = data[f\"Time Series ({interval})\"]\n",
        "        df = pd.DataFrame.from_dict(time_series, orient=\"index\")\n",
        "        df.reset_index(inplace=True)\n",
        "        df.rename(columns={\"index\": \"timestamp\"}, inplace=True)\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"Unexpected data format for {symbol}: {data}\")\n",
        "        return None\n",
        "\n",
        "stock_data = fetch_stock_data(\"AAPL\")\n",
        "if stock_data is not None:\n",
        "    print(stock_data.head())\n",
        "else:\n",
        "    print(\"Could not retrieve stock data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3muMVSN3PJ-",
        "outputId": "7b850295-0333-4042-ac88-769cfe39c548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             timestamp   1. open   2. high    3. low  4. close 5. volume\n",
            "0  2025-03-25 19:55:00  224.1300  224.3300  224.1000  224.2400      3316\n",
            "1  2025-03-25 19:50:00  224.2000  224.3300  224.0700  224.1000       738\n",
            "2  2025-03-25 19:45:00  224.1500  224.3300  224.0700  224.2800      2743\n",
            "3  2025-03-25 19:40:00  224.1500  224.1500  224.0700  224.0700       834\n",
            "4  2025-03-25 19:35:00  224.1000  224.1500  224.0500  224.0701       546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#    Data Collection - Rough\n",
        "\n",
        "1.   Fetch trading data from Alpha Vantage\n",
        "2.   Detect potential market manipulation using Isolation Forest\n",
        "3.   Mock implementation of social media sentiment collection\n",
        "\n"
      ],
      "metadata": {
        "id": "f3UoZNVs0owj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import requests\n",
        "\n",
        "class MarketManipulationDetector:\n",
        "    def __init__(self, alpha_vantage_key):\n",
        "        self.alpha_vantage_key = alpha_vantage_key\n",
        "        self.trading_data = None\n",
        "        self.sentiment_data = None\n",
        "\n",
        "    def fetch_trading_data(self, symbol):\n",
        "        url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={self.alpha_vantage_key}\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            raw_data = response.json()\n",
        "            self.trading_data = pd.DataFrame.from_dict(\n",
        "                raw_data.get('Time Series (Daily)', {}),\n",
        "                orient='index'\n",
        "            )\n",
        "            self.trading_data.columns = [\n",
        "                'open', 'high', 'low', 'close', 'volume'\n",
        "            ]\n",
        "            self.trading_data = self.trading_data.astype(float)\n",
        "\n",
        "    def detect_anomalous_trading(self):\n",
        "        if self.trading_data is None:\n",
        "            raise ValueError(\"Trading data not loaded\")\n",
        "\n",
        "\n",
        "        features = ['volume', 'close']\n",
        "        X = self.trading_data[features]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        clf = IsolationForest(contamination=0.1, random_state=42)\n",
        "        y_pred = clf.fit_predict(X_scaled)\n",
        "        self.trading_data['is_anomaly'] = y_pred == -1\n",
        "\n",
        "        return self.trading_data[self.trading_data['is_anomaly']]\n",
        "\n",
        "    def collect_social_sentiment(self, symbol):\n",
        "        #  without StockTwits API\n",
        "\n",
        "        fake_sentiments = {\n",
        "            'bullish': 0.6,\n",
        "            'bearish': 0.3,\n",
        "            'neutral': 0.1\n",
        "        }\n",
        "        return fake_sentiments\n",
        "\n",
        "def main():\n",
        "\n",
        "    detector = MarketManipulationDetector(alpha_vantage_key='QT13WY791JO16QMJ')\n",
        "    detector.fetch_trading_data('INFY')\n",
        "\n",
        "    anomalies = detector.detect_anomalous_trading()\n",
        "    print(\"Potential Manipulative Trading Days:\")\n",
        "    print(anomalies)\n",
        "\n",
        "\n",
        "    sentiment = detector.collect_social_sentiment('INFY')\n",
        "    print(\"\\nSocial Media Sentiment:\")\n",
        "    print(sentiment)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDUXnDAq-ZR5",
        "outputId": "20aa68da-c4a7-4044-a4cb-19da435ccdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Potential Manipulative Trading Days:\n",
            "             open    high      low  close      volume  is_anomaly\n",
            "2025-03-28  18.37  18.482  18.1050  18.17   7866062.0        True\n",
            "2025-03-27  18.70  18.780  18.5950  18.67   6249534.0        True\n",
            "2025-03-21  18.41  18.430  18.1700  18.32  18677618.0        True\n",
            "2025-03-20  18.33  18.390  17.9001  18.06  19376214.0        True\n",
            "2025-03-13  18.50  18.585  18.2600  18.29  10913566.0        True\n",
            "2025-03-12  18.49  18.645  18.3400  18.50  15292391.0        True\n",
            "2025-03-11  19.13  19.200  18.8100  18.97  17695135.0        True\n",
            "2025-01-16  22.60  22.600  21.3100  21.57  22922717.0        True\n",
            "2024-12-19  23.18  23.620  23.1000  23.42   9178696.0        True\n",
            "2024-12-13  23.52  23.630  23.2800  23.40   4443501.0        True\n",
            "\n",
            "Social Media Sentiment:\n",
            "{'bullish': 0.6, 'bearish': 0.3, 'neutral': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpha_vantage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYjws_ZGAVhd",
        "outputId": "475a0c9f-2899-4afd-e7bd-59bd9c1aa6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alpha_vantage\n",
            "  Downloading alpha_vantage-3.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from alpha_vantage) (3.11.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from alpha_vantage) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->alpha_vantage) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->alpha_vantage) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->alpha_vantage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->alpha_vantage) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->alpha_vantage) (2025.1.31)\n",
            "Downloading alpha_vantage-3.0.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: alpha_vantage\n",
            "Successfully installed alpha_vantage-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main code"
      ],
      "metadata": {
        "id": "sU4tfEFVzcG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from textblob import TextBlob\n",
        "from alpha_vantage.timeseries import TimeSeries\n",
        "\n",
        "\n",
        "#stock data collection\n",
        "ALPHA_VANTAGE_API_KEY = \"ED3T9IQN5OD495QC\"\n",
        "STOCK_SYMBOL = \"AAPL\"\n",
        "\n",
        "ts = TimeSeries(key=ALPHA_VANTAGE_API_KEY, output_format='pandas')\n",
        "data, meta_data = ts.get_daily(symbol=STOCK_SYMBOL, outputsize='compact')\n",
        "\n",
        "\n",
        "data.to_csv(\"stock_data.csv\") # storing stock data as a CSV file\n",
        "print(\"Stock data saved successfully.\")\n",
        "\n",
        "# StockTwits Data\n",
        "def fetch_stocktwits_data(symbol):\n",
        "    url = f\"https://api.stocktwits.com/api/2/streams/symbol/{symbol}.json\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def analyze_sentiment(messages):\n",
        "    sentiments = []\n",
        "    for msg in messages:\n",
        "        text = msg['body']\n",
        "        sentiment = TextBlob(text).sentiment.polarity\n",
        "        sentiments.append({'timestamp': msg['created_at'], 'text': text, 'sentiment_score': sentiment})\n",
        "    return sentiments\n",
        "\n",
        "stocktwits_data = fetch_stocktwits_data(\"TCS\")\n",
        "if stocktwits_data:\n",
        "    messages = stocktwits_data['messages']\n",
        "    sentiment_analysis = analyze_sentiment(messages)\n",
        "    df_sentiment = pd.DataFrame(sentiment_analysis)\n",
        "    df_sentiment.to_csv(\"sentiment_data.csv\", index=False)\n",
        "    print(\"Sentiment data saved successfully.\")\n",
        "else:\n",
        "    print(\"Failed to fetch StockTwits data.\")\n",
        "\n",
        "\n",
        "def analyze_news_sentiment(news_text):\n",
        "    return TextBlob(news_text).sentiment.polarity\n",
        "\n",
        "news_text_sample = \"Stock markets rally as tech stocks soar.\"\n",
        "print(\"Sample News Sentiment Score:\", analyze_news_sentiment(news_text_sample))\n"
      ],
      "metadata": {
        "id": "O2hbSfuShXEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36301a50-595c-4d54-9a35-06d167283768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock data saved successfully.\n",
            "Failed to fetch StockTwits data.\n",
            "Sample News Sentiment Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feedparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElDqIeTsr4b1",
        "outputId": "74a8e880-864f-41ee-cc1c-009b990ca01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=208730de486f11e99ae97bbc567df4a5a2853405ec2ad5fb060084893a8550ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.11 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n",
        "1. Fetch daily stock data using Alpha Vantage API\n",
        "2. Analyze sentiment of messages\n",
        "3. Analyze sentiment of news text\n",
        "\n"
      ],
      "metadata": {
        "id": "JUjm350A2Gko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from textblob import TextBlob\n",
        "from alpha_vantage.timeseries import TimeSeries\n",
        "import feedparser\n",
        "\n",
        "ALPHA_VANTAGE_API_KEY = \"ED3T9IQN5OD495QC\"\n",
        "STOCK_SYMBOL = \"AAPL\"\n",
        "STOCKTWITS_API_URL = \"https://api.stocktwits.com/api/2/streams/symbol/{symbol}.json\"\n",
        "\n",
        "def fetch_stock_data(symbol, api_key):\n",
        "    try:\n",
        "        ts = TimeSeries(key=api_key, output_format='pandas')\n",
        "        data, meta_data = ts.get_daily(symbol=symbol, outputsize='compact')\n",
        "        data.to_csv(\"stock_data.csv\")\n",
        "        print(f\"\\nStock data for {symbol} saved successfully.\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching stock data: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_stocktwits_data(symbol):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        url = STOCKTWITS_API_URL.format(symbol=symbol)\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            print(f\"Successfully fetched StockTwits data for {symbol}\")\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"Failed to fetch StockTwits data. Status code: {response.status_code}\")\n",
        "            print(f\"Response content: {response.text}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error in fetching StockTwits data: {e}\")\n",
        "        return None\n",
        "\n",
        "def analyze_sentiment(messages):\n",
        "    sentiments = []\n",
        "    for msg in messages:\n",
        "        text = msg.get('body', '')\n",
        "        sentiment = TextBlob(text).sentiment.polarity\n",
        "        sentiments.append({\n",
        "            'timestamp': msg.get('created_at', 'N/A'),\n",
        "            'text': text,\n",
        "            'sentiment_score': sentiment\n",
        "        })\n",
        "    return sentiments\n",
        "\n",
        "def get_google_news_rss(stock_name):\n",
        "    url = f\"https://news.google.com/rss/search?q={stock_name}+stock\"\n",
        "    feed = feedparser.parse(url)\n",
        "\n",
        "    news_list = []\n",
        "    for entry in feed.entries[:5]:  # Fetch top 5 news articles\n",
        "        news_list.append({\"title\": entry.title, \"link\": entry.link})\n",
        "\n",
        "    return news_list\n",
        "\n",
        "news_data = get_google_news_rss(\"TCS\")\n",
        "for news in news_data:\n",
        "    print(\"\\n\",news[\"title\"], \"-\", news[\"link\"])\n",
        "\n",
        "def analyze_news_sentiment(news_data):\n",
        "    return TextBlob(news_data).sentiment.polarity\n",
        "\n",
        "def main():\n",
        "    stock_data = fetch_stock_data(STOCK_SYMBOL, ALPHA_VANTAGE_API_KEY)\n",
        "    stocktwits_data = fetch_stocktwits_data(STOCK_SYMBOL)\n",
        "\n",
        "    if stocktwits_data and 'messages' in stocktwits_data:\n",
        "        sentiment_analysis = analyze_sentiment(stocktwits_data['messages'])\n",
        "        df_sentiment = pd.DataFrame(sentiment_analysis)\n",
        "        df_sentiment.to_csv(\"sentiment_data.csv\", index=False)\n",
        "        print(\"Sentiment data saved successfully.\")\n",
        "    else:\n",
        "        print(\"No messages found in StockTwits data.\")\n",
        "    news_text_sample = \"Stock markets rally as tech stocks soar.\"\n",
        "    print(\"Sample News Sentiment Score:\", analyze_news_sentiment(news_text_sample))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9meFyDis_mnP",
        "outputId": "f7d6ea49-327e-404a-8431-eb620acd0bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TCS, Infosys, HDFC Bank, HCL Tech among 5 key stocks to declare interim dividend in April 2025 - Mint - https://news.google.com/rss/articles/CBMi8wFBVV95cUxQOXJ0TEd1UWVmTXRSS0UxYThjNnJjaS1SWWJReGdLS1RYMVAwR2pwaE00OExTQzhKeFdUckVYTlh3dFNZQ19vQkV2TG5zdVRqd19ZVXVaRlF4TFk4MGZBR2EtV3YzZXI5RkNzU01icHZCbVo0YTdhemstVU1EN2wwaUdUYnFINk5DRTlsbk95UTJfeFQ0WUYyVkxFRFZKaG5Cc212QVFycjJxVFZVRkZuN09oQjBPRF9fTmc5RzlrZG1tMW1HMjJuUHpHWWJSU3RtT2NsOWpPbkJtQ3hxMUJWRTA5c0lnLTE3WXhGS21tXzQ3OUXSAfgBQVVfeXFMTXd6aFRBUEROLW95SDdmeVU0dldqREJxdGpIOUJYV2x4XzFYS21zNlNZa3JmR1o5ZXpYVEQxSVB3NVVBblRWb0haenFVSGJqdHFONzllUlFXcVhINlplN2Vicm5kQS1oZlZIbFo5ZHltNVVscDBIdXl0Nm5EY1Zud3UtRmZMQmF4SHZlaWo4NGdCVEFDU1RyNlUtcDE2cGxTdGdfR01TdGFrTG8wVU93TlhLTktFNXVHZE50ejN0VUNTNnNxRzh4RmlwejJQNkdoTmNFUWtYZTYtcmR3cGdhazdibnJ6a0pmS3pyR0s1TGU3WHhiZTE3Tjg?oc=5\n",
            "\n",
            " 32% target price slash! Goldman flags big risks for TCS, Infosys & other IT stocks amid US worries - The Economic Times - https://news.google.com/rss/articles/CBMi3AFBVV95cUxPdVdENUlnZEhJb213YkxKX2R0RE51Sm9FRGlRbGhwQlNXR3dfNVRpeGZNVHZ3b09CWGhEak9hdmlyOTFzekZ6dGdORVhhNWZIR3FjOG9FTkNoR0ZfNWxVS2RQQnhRYjgzSUZPZGdRTjc2bUdhUG1SWWc3OVdOVF9VRjNZeURCWjNSQlo4LVRKcVVYb0lGVmpRR1NkUFJEMThQR1dvUzVIZDNFczQ4WmFiNzhLbXdUT0FrUWVkNmpDbl9CRWlzaC1vTmk1M2huQnRvWDVIREsxMU8tOFU50gHiAUFVX3lxTFBteEZETU1iQkNMUUZoSzZlUURqaTdVNEVCVlEyZmdLdUZwVmpDS2FrSjEyZ1ZJSzhxVldETVpzYjVGbFhaZGVXVTdXazZzZHY5c3VYSUM4U2hGejZHQ0pKNFRkTjB4R1hvdkRnbFlpZjhkLVl0U3NBZVpxeS1fMU1hTUpTU190Ym5YaTZ6UzBCQXUwNE0zbWV0VkJ3cXlNRTZuVzA1R0VueUJqTWo5SHJVZFJkcXhUWWpQOXRKWXpud29JU1BEQkx4VFRjd1YzbWUzNEMwWk9KbU5LcjgxYTdkcHc?oc=5\n",
            "\n",
            " LTIMindtree shares downgraded by Goldman Sachs, price targets cut for TCS, Infosys - CNBCTV18 - https://news.google.com/rss/articles/CBMi0AFBVV95cUxPaFFTTmNJN0VsQVJBZENhTFRuMjcwZWtsUGswc0dMRTQtbmVCTDVWMFBzRlNXSHN6Q0t6SzR4N1pCeUFkRmZERjFsOWJBckN4UUhsaXU2bWd4R0dzSFN2LUt2UjB3amhTR25uOVA4UndRbmhhNndtMDRfblZaTEdVQUZMaUdqQ2pkTk5VcDEzOGtmdmRYZ2xSTUFkakZBbWx0aUpsbGo0blBEYXdEU3hrR3FfSlBDZHNNZ2RCSC14RWFvSlNWM0REcjA5QnEzWEVs0gHWAUFVX3lxTFBQdHFrZ3M5ZC14ajZkSkJnOTZGNnprNWhvQ09zcDFqUmpHS1pNLWk0TVYwOGFLM0hvenBUSnpLSFRoWHdMcHZhc3ZnVEhGXzJENkJfMXVQdDhZcnhUb1k5UzNqTk1YMTREOEprTDdfTkxxa2xBZE04S2FkRjZIdktlQUNCdngyQlljOWZJNzRQR3FxWXdYU1lhQ1pOazRJSnhBRjllMWN0T0tUbmlLTENTWDlkNkc2RWtOem14Ull3bVhKb0FtOGFPR2tsalZBcFp0NkxBNFE?oc=5\n",
            "\n",
            " IT Stocks, Wipro, Infosys, TCS Share Price Highlights: Wipro ends nearly 2% higher, Infosys, TCS, HCL Tech shares end flat - BusinessLine - https://news.google.com/rss/articles/CBMi2gFBVV95cUxOcldqU0kzVHhmVkRQRVhXVzhiMHA2WDRZM3htb2hxQVpqWmxFVGp1MTV6OWlIZFg3YnFwUmRlY2RnM1BnLVJvaVdUS2FCXzlHOHk3QzdubW1sS0JxeVhtcFVmN3Rqb3RNalVHRHVzaFZ2eGp0RGdKTUlJTzUzTFBOaHFkaWwzN1J5LVdoMXgyWmZOS09zMVd0MmxzZExUQUJPOHdiZ2tSMnF3R2tXWURzaEFKNVpjd21jaEI3R2daU0gzZmI1S0tva3RjV2xYUjZyd2xNZTZhS0o3dw?oc=5\n",
            "\n",
            " TCS, Infosys, HDFC Bank, HCL Tech among 5 key stocks to declare interim dividend in April 2025 - MSN - https://news.google.com/rss/articles/CBMi2wFBVV95cUxQUzN6YlQtdEJ6WDJUTFN5aFdCaFlxdGxSeXRoZzZvOFlfU3cyZjJITGUzOG5aRV9WXzBWd2tDNmZrbi1tWDg2YjNzZGRGNy1wczl2eDRnNG5qZV9Tb3V1b0dtWEZGdzUtUVhQTERGTC1KU2tUbGhpNGF0cEd2UURCcFZkdWhyNVhRN1lPYTFNVHpZSUJIbWJBQTJycWhNV0lOQTVfLWI4bVB1MzJjeDdDMFozTkd2NmFybEd6ZmpEc3lSUUN5M0Z2XzN0X0VFekt2dHY3dElHbnFEdzQ?oc=5\n",
            "\n",
            "Stock data for AAPL saved successfully.\n",
            "Successfully fetched StockTwits data for AAPL\n",
            "Sentiment data saved successfully.\n",
            "Sample News Sentiment Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W50s494IrdhO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}